# Что такое бинарное дерево поиска?
**Бинарное дерево поиска (BST)** - это структура данных, вид дерева, в котором узел может иметь максимум 2 дочерних узла. При этом узлы располагаются по следующим правилам:
- Левые потомки содержат ключи **меньшие либо равные**, чем ключ родителя.
- Правые потомки содержат ключи **большие**, чем ключ родителя.

![Бинарное дерево поиска](https://static.packt-cdn.com/products/9781789801736/graphics/C09581_08_02.jpg)

Так, все узлы меньше либо равные корню 7, располагаются в левой части, или же в *левом поддереве*. Остальные узлы располагаются справа, в *правом поддереве*.

**Важно отметить, что правила расположения выше выполняются для каждого поддерева.** ***Поддерево*** - это дерево внутри еще одного дерева. Мы как бы выделяем часть из дерева, и рассматриваем только ее, как отдельное дерево. Так, у нас есть поддерева с корнем 5, c корнем 12, с корнем 3, 9, 15 и так далее.

## Реализация BST
На прошлом уроке было сказано, что деревья реализуются через узлы (node). В бинарном дереве поиска каждый узел может иметь максимум два дочерних узла, один из которых располагается слева, а другой справа. Поэтому узел принимает такой вид:

```python
class Node:
    def __init__(self, key):
        self.key = key
        self.left = None
        self.right = None
```

Теперь, что же насчет самого дерева? Само дерево будет представлять собой класс, содержащий корень дерева (его начало), а также методы для выполнения операций.

```python
class BinarySearchTree:
    def __init__(self):
        self.root: Node | None = None
```

### Вставка данных в дерево
Что подразумевает вставка данных в дерево? 

*Во-первых*, это вставка в правильное место. К примеру, если корнем дерева является узел 8, то мы не можем вставить узел 10 слева от него, так он больше корня, а значит, должен находиться справа.

*Во-вторых*, должно быть место для вставки узла. То есть, надо по правилам искать тот узел, у которого левый и правый дочерний узел соответственно еще не создан.

Как же это сделать? Возможно, некоторые заметили, что дерево состоит из поддеревьев - из маленьких подзадач. А значит, вероятно мы можем использовать рекурсию. И да, так и есть.

Какой у нас базовый случай?
Прежде чем начинать поиск, надо проверить, а есть ли у нас вставленные узлы? Мы просто проверяем, определён ли у нас корень, и если нет, то создаем его.

```python
def insert(self, key):
        if self.root is None:
            self.root = Node(key)
        else: # рекурсивный случай
	        ...
```

Ладно, а что же насчет рекурсии? Логику вставки и поиска мы выведем в отдельную вспомогательную функцию `__insert_recursive()`. 
Данная функция будет по правилам (больше-меньше) искать позицию для вставки узла. Что она должна принимать? Это узел, на котором мы остановились, а также данные для вставки:

```python
def __insert_recursive(self, node, key):
```

Дальше наша функция должна сравнивать значение нашего текущего узла (используя параметр `node`) со значением для вставки (`value`): если больше текущего узла (или же корня поддерева), то рассматриваем для вставки правый дочерний узел. Иначе левый.

```python
def __insert_recursive(self, node, key):
        if key < node.key:
			...
        elif key > node.key:
			...
```

Какой будет базовый случай для нас в этой функции? Базовым случаем будет являться незанятый узел, иными словами, `node.left` или `node.right` будет равняться `None`. Тогда это означает, что мы нашли место для вставки, и создаем на этом месте новый узел с нашими данными.

```python
def __insert_recursive(self, node, key):
        if key < node.key:
            if node.left is None:
                node.left = Node(key)
            else:
                self._insert_recursive(node.left, key)

        elif key > node.key:
            if node.right is None:
                node.right = Node(key)
            else:
                self._insert_recursive(node.right, key)
```

Базовый случай определен. Если же у узла имеются дочерние узлы, то нам нужно продолжать искать позицию в поддереве. Мы просто вызываем нашу же функцию, но теперь передаем в качества узлы левый или правый дочерний узел.

Теперь осталось лишь использовать эту вспомогательную функцию внутри нашей основной.

Для понимания нашего поиска необходимо разобраться в рекурсии. Также для большего понимания составьте рисунок бинарного дерево поиска, и попробуйте вставить новый узел, следуя нашему программному алгоритму. Это должно придать ясности.

Алгоритм на словах будет такой:
1. Начинаем с корня. 
2. Сравниваем  значение узла со значением для вставки
3. Если значение для вставки меньше либо равно значению узла, то смотрим левый дочерний узел. Переходим на шаг 5
4. Если значение для вставки больше значения узла, то смотрим правый дочерний узел. Переходим на шаг 5
5. Является новый узел для рассмотрения незанятым? Если да, то вставляем значение. Иначе переходим на шаг 2.

### Поиск в дереве узла

Если вы разобрались с алгоритмом выше, то с этим вы тоже почти разобрались. Пусть нам необходимо найти узел с нужным значением. Опять же будем реализовывать через рекурсию. Метод будет принимать текущий узел для рассмотрения и значение которое нужно найти. А возвращать либо найденный узел, либо `None`:

Базовым случаем будет выполнение условия, что `node.key` == `key` либо же `node is None`. Иначе мы проходимся по дереву используя наши правила для расстановки узлов.

```python
def search(self, key):
        """Поиск узла по ключу"""
        return self._search_recursive(self.root, key)

def __search_recursive(self, node, key):
        if node is None or node.key == key:
            return node

        if key < node.key:
            return self._search_recursive(node.left, key)
        return self._search_recursive(node.right, key)
```

Что можно сделать с полученным узлом? Мы можем посмотреть его дочерние элементы, а также использовать для нахождения минимального значения в поддереве, где корнем будет являться он.

Однако нельзя напрямую менять ему значение или же удалять его (приравнивать к `None`). Мы можем нарушить структуру дерева, или же потерять потомков узла, а значит и часть дерева.

Теперь перейдем к наиболее сложной в реализации операции - удаления узла.

### Удаление узла в дереве

Когда мы хотим удалить узел, может возникнуть несколько вариантов событий:
1. У узла нет потомков (лист)
2. У узла есть один потомок - левый или правый
3. У узла есть и левый, и правый потомок

![Бинарное дерево поиска](https://habrastorage.org/r/w1560/getpro/habr/upload_files/cd1/a76/759/cd1a76759cf0d9253b22925460225bb7.png)

В 1-ом случае мы просто приравниваем найденный узел к `None`. Ничего не нарушается. Так, если мы хотим удалить узел 0, являющийся листом, просто теперь его родительский узел 1 будет ссылаться на `None` в левом дочернем узле.

Во 2-ом случае все также довольно просто. Если у узла только один потомок, то нам необходимо сделать так, чтобы родитель удаляемого узла начал ссылаться на существующий дочерний узел удаляемого узла.

Пусть мы хотим удалить узел 1. У него есть дочерний узел 0. Это 2-ой случай. Нам необходимо сделать так, чтобы родительский узел (2) удаляемого узла ссылался на дочерний узел (0) удаляемого узла. Проще говоря, мы просто меняем ссылку. И левым дочерним узлом 2 станет узел 0, а не  узел 1.

3-ий случай самый сложный. Но если описать его кратко, то:
1. Мы ищем самый минимальный элемент в правом поддереве удаляемого узла
2. Меняем значение удаляемого узла на минимальный
3. Удаляем минимальный узел из правого поддерева

На примере удаляемого узла 6. Смотрим в его правое поддерево (или же ветвь), минимальным элементом является узел 7. Приравниваем значение нашего удаляемого узла к 7. После чего удаляем узел 7.

Теперь напишем метод для выполнения удаления узла. Он опять будет состоять из двух методов: к одному мы обращаемся, а второй используем в работе первого для рекурсии.

```python
 def delete(self, key):
        self.root = self.__delete_recursive(self.root, key)
```

Процесс похожий: сначала надо найти удаляемый узел, поэтому наш рекурсивный метод принимает текущий рассматриваемый узел.

Стоит учесть, что удаляемого узла может и не быть, поэтому надо остановить поиск, если узел равняется `None`:

```python

def __delete_recursive(self, node, key):
        if node is None:
            return node
        ...
```

Теперь нужно идти по дереву в соответствии с правилами BST:

```python
    def __delete_recursive(self, node, key):
        if node is None:
            return node
            
        if key < node.key: # идем в левую ветвь
            node.left = self.__delete_recursive(node.left, key)
        elif key > node.key: # идем в правую ветвь
            node.right = self.__delete_recursive(node.right, key)
```

Когда мы нашли удаляемый узел (`key == node.key`, или же просто случай `else`), необходимо определить какой случай удаления у нас - лист, с одним потомком или двумя потомками.

```python
def __delete_recursive(self, node, key):
        else:
            # Узел с одним потомком или без потомков
            if node.left is None:
                return node.right
                
            elif node.right is None:
                return node.left

            # Узел с двумя потомками: находим минимальный в правом поддереве
            min_node = self.__find_min(node.right)
            node.key = min_node.key # меняем значение на минимальный узел
            node.right = self.__delete_recursive(node.right, min_node.key) # удаляем минимальный узел правого поддерева

        return node # возвращаем узел
```

Реализация метода нахождения минимального узла:

```python
def __find_min(self, node):
        current = node
        while current.left is not None:
            current = current.left
        return current
```

Полная реализация:
```python
def delete(self, key):
	self.root = self.__delete_recursive(self.root, key)

def __delete_recursive(self, node, key):
	if node is None:
		return node

	if key < node.key:
		node.left = self.__delete_recursive(node.left, key)
		
	elif key > node.key:
		node.right = self.__delete_recursive(node.right, key)
	else:
		if node.left is None:
			return node.right
			
		elif node.right is None:
			return node.left
		# Узел с двумя потомками: находим минимальный в правом поддереве
		
		min_node = self.__find_min(node.right)
		node.key = min_node.key
		node.right = self.__delete_recursive(node.right, min_node.key)

	return node

def __find_min(self, node):
	current = node
	while current.left is not None:
		current = current.left
	return current
```

Могли остаться вопросы, а что мы вообще возвращаем и зачем? Мы возвращаем либо измененные узел (3 узел), либо же ссылку на другой узел (1-2 случай).

Опять же рекомендую рассмотреть деревья и разные случаи удаления по ним с точки зрения рекурсии и стека вызова. Также можете использовать инструменты для визуализации рекурсия конкретного алгоритма - очень помогает.

Рекомендую посмотреть следующее видео от Балакирева - https://www.youtube.com/watch?v=mdkwm5FUpFs&list=PLA0M1Bcd0w8x4jEp1r_aN3xlnlbfx9RQ2&index=20. 

## Big O бинарного дерева поиска

| **Операция**      | **Временная сложность**|
|-------------------|-------------------------------|
| **Поиск (`search`)** | `O(log n)` 
| **Вставка (`insert`)** | `O(log n)` 
| **Удаление (`delete`)** | `O(log n)`

Почему `O(log n)`? Во-первых стоит сказать, что и вставка, и удаление перед выполнением своих действий выполняют поиск узла. А что же происходит при поиске? На каждом шаге мы избавляемся от *половины* рассматриваемых узлов.

К примеру, у нас есть бинарное дерево поиска из 8 элементов.  Корневым элементом является узел 4. И нам необходимо найти узел 6. Что мы сделаем? Раз узел 6 больше нашего корня 4, то нам необходимо искать в правой ветви узла. И мы избавляемся от половины элементов! И так каждый раз. 

Когда на каждом шаге алгоритма мы избавляемся от какой-то части данных, такой алгоритм имеет *логарифмическую* временную сложность. 

Однако мы рассмотрели идеальный случай. Я допустил, что в моем дереве что в левой ветви (поддереве), что в правой ветви одинаковое количество элементов. Но никто этого не гарантирует. И вот мы переходим к проблеме бинарного дерева поиска.

## Проблема бинарного дерева поиска
Давайте будем добавлять элементы от 0 до 9 подряд в наше дерево: сначала 0, затем 1, затем 2 и так далее.

Получится нечто такое:

![Вырожденное дерево](https://media.proglib.io/posts/2021/09/29/c2f95ca8249b5bb596c40234d2f2666e.png)

Ничего не напоминает? Это ведь тот же связный список! То, что представлено на изображении, называют *вырожденным деревом*. Высота такого дерева будет равна n - 1 (где n - количество вершин в дереве).

Почему нас это должно волновать? Оказывается, ***временная сложность операций дерева пропорциональна высоте дерева***. Чем меньше высота дерева, тем меньше временная сложность.

Обычно, высота дерева *h* = log2n. Но в случае с вырожденным деревом она будет равняться `O(n - 1)` = `O(n)`.

### Балансировка дерева
К счастья, мы можем изменить высоту дерева. Это процедура называется *балансировкой дерева*, когда мы перестраиваем узлы так, чтобы сделать высоту минимальной.

Балансировка дерева является дорогой операцией, поэтому ее производят раз в несколько вставок или удалений узлов. И были созданы деревья, которые автоматически выполняют балансировку после удаления или вставки узлов. Такие деревья называют *сбалансированными*. О них будет рассказано в следующих уроках

## Что дальше?
В следующем уроке мы рассмотрены способы обхода узлов дерева, а затем познакомимся со сбалансированными деревьями

## Заключение

1. **Основные свойства BST**  
   - Каждый узел имеет **не более двух потомков**.  
   - Левые потомки содержат ключи **≤ родителя**, правые — **> родителя**.  
   - Правило применяется **рекурсивно ко всем поддеревьям**.

2. **Временная сложность**  
   - **Средний случай** (сбалансированное дерево): Поиск, вставка, удаление — `O(log n)`.  
   - **Худший случай** (вырожденное дерево → список) - `O(n)`

1. **Советы**
   - Избегайте прямого изменения ключей узлов — это нарушает структуру BST.  
   - В реальных проектах предпочтительнее готовые оптимизированные структуры (например, `SortedDict` в Python).  




 












